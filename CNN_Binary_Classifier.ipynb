{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1750081672996,
     "user": {
      "displayName": "teitur",
      "userId": "14435076508088469441"
     },
     "user_tz": 0
    },
    "id": "lmdAuBg1qZrF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class _Branch(nn.Module):\n",
    "    def __init__(self, channel_sequence, kernel_sizes, paddings, strides, pool_sizes, pool_strides, dropout_rates):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_channels = 1\n",
    "\n",
    "        for i, (out_channels, k, p, s) in enumerate(zip(channel_sequence, kernel_sizes, paddings, strides)):\n",
    "            layers.extend([\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=k, padding=p, stride=s, bias=False),\n",
    "                nn.BatchNorm1d(out_channels),\n",
    "                nn.ReLU()\n",
    "            ])\n",
    "            in_channels = out_channels\n",
    "\n",
    "            # add pooling and dropout after each block except the last\n",
    "            if i < len(pool_sizes):\n",
    "                layers.append(nn.MaxPool1d(kernel_size=pool_sizes[i], stride=pool_strides[i]))\n",
    "                if dropout_rates[i] > 0: # -> 0 dropout rate? Don't add the layer ya dingus\n",
    "                    layers.append(nn.Dropout(dropout_rates[i]))\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class CNN_BinaryClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    n-branched convolutional neural network for binary sleep classification.\n",
    "    Input is arbitrary, i don't really give a care. Please have at least about 1000 samples? please?\n",
    "\n",
    "    An example of a model predicting N3 with 3000 samples as input:\n",
    "    X -> 3000 samples of whatever data\n",
    "    y -> 0 or 1\n",
    "      0 -> NOT N3\n",
    "      1 -> N3\n",
    "\n",
    "    branch_configs = {\n",
    "      \"left\": {\n",
    "          \"channel_sequence\": [32, 64, 64],\n",
    "          \"kernel_sizes\": [22, 8, 8],\n",
    "          \"paddings\": [22//2, 3, 3],\n",
    "          \"strides\": [6, 1, 1],\n",
    "          \"pool_sizes\": [8, 4],\n",
    "          \"pool_strides\": [8, 4],\n",
    "          \"dropout_rates\": [0.1, 0.0]  # dropout only after first pool\n",
    "        },\n",
    "      \"right\": {\n",
    "          \"channel_sequence\": [32, 64, 64],\n",
    "          \"kernel_sizes\": [400, 6, 6],\n",
    "          \"paddings\": [175, 2, 2],\n",
    "          \"strides\": [50, 1, 1],\n",
    "          \"pool_sizes\": [4, 2],\n",
    "          \"pool_strides\": [4, 2],\n",
    "          \"dropout_rates\": [0.1, 0.0]  # dropout only after first pool\n",
    "        }\n",
    "    }\n",
    "\n",
    "    model_args = {\n",
    "        \"name\": \"MyN3Classifier\",\n",
    "        \"n_samples\": 3000,\n",
    "        \"branch_configs\": branch_configs\n",
    "    }\n",
    "\n",
    "    model = SleepstageClassifier(**model_args)\n",
    "    \"\"\"\n",
    "    WAKE = 0\n",
    "    N1 = 1\n",
    "    N2 = 2\n",
    "    N3 = 3\n",
    "    REM = 4\n",
    "\n",
    "    def __init__(self, name, n_samples, branch_configs):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.branches = nn.ModuleDict()\n",
    "        self.branch_output_sizes = {}\n",
    "\n",
    "        for name, config in branch_configs.items():\n",
    "            self.branches[name] = _Branch(**config)\n",
    "\n",
    "        # output sizes using dummy input\n",
    "        with torch.inference_mode():\n",
    "            dummy = torch.zeros(1, 1, n_samples)\n",
    "            for name, branch in self.branches.items():\n",
    "                branch.eval()\n",
    "                out = branch(dummy)\n",
    "                self.branch_output_sizes[name] = out.numel() // out.shape[0]\n",
    "                branch.train()\n",
    "\n",
    "        total_features = sum(self.branch_output_sizes.values())\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(total_features, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, 32), # 32 vector embedding :)\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = [branch(x).flatten(1) for branch in self.branches.values()]\n",
    "        combined = torch.cat(outputs, dim=1)\n",
    "        x = self.fc(combined)\n",
    "        return self.classifier(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIPcHs4ptYdg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "def train_model(model, device, train_loader, test_loader, pos_weight, lr=2.5e-5, wd=1e-4, p=5, f=0.5, epochs=25, output_period=1, log_tensorboard=False):\n",
    "    if log_tensorboard:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        writer = SummaryWriter(f'runs/experiment_{timestamp}')\n",
    "\n",
    "    if device.type == \"cpu\":\n",
    "        print(\"WARNING: Using CPU as device. This may take a while...\")\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device)) # binary cross-entropy\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd) # Adam optimizer for Windows\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"max\", patience=p, factor=f) # lowers learning rate by a factor of f every p epochs without significant gain in F1 score\n",
    "    best_f1 = 0.0\n",
    "    best_epoch = -1\n",
    "    best_model_state = None\n",
    "    print(f\"running for {epochs} epochs.\")\n",
    "\n",
    "    train_losses_data, test_losses_data = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch).squeeze()\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        all_preds, all_targets, all_probs = [], [], []\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device).float()\n",
    "                outputs = model(X_batch).squeeze()\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                test_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "                probs = torch.sigmoid(outputs)\n",
    "                preds = probs > 0.5\n",
    "\n",
    "                all_probs.extend(probs.cpu().numpy().flatten())\n",
    "                all_preds.extend(preds.cpu().numpy().flatten())\n",
    "                all_targets.extend(y_batch.cpu().numpy().flatten())\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        train_losses_data.append(train_loss)\n",
    "        test_losses_data.append(test_loss)\n",
    "\n",
    "\n",
    "        all_targets_np = np.array(all_targets)\n",
    "        all_preds_np = np.array(all_preds)\n",
    "\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            all_targets_np, all_preds_np, average=\"binary\", zero_division=0\n",
    "        )\n",
    "        accuracy = accuracy_score(all_targets_np, all_preds_np)\n",
    "\n",
    "        scheduler.step(f1)\n",
    "\n",
    "        if log_tensorboard:\n",
    "            writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "            writer.add_scalar('Loss/Test', test_loss, epoch)\n",
    "            writer.add_scalar('Metrics/Precision', precision, epoch)\n",
    "            writer.add_scalar('Metrics/Recall', recall, epoch)\n",
    "            writer.add_scalar('Metrics/F1', f1, epoch)\n",
    "            writer.add_scalar('Metrics/Accuracy', accuracy, epoch)\n",
    "\n",
    "\n",
    "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "        if log_tensorboard:\n",
    "            writer.add_scalar('Learning Rate', current_lr, epoch)\n",
    "            writer.add_pr_curve('PR_Curve',\n",
    "                                np.array(all_targets),\n",
    "                                np.array(all_probs),\n",
    "                                global_step=epoch)\n",
    "\n",
    "        if epoch % 5 == 0 and log_tensorboard:\n",
    "            for name, param in model.named_parameters():\n",
    "                writer.add_histogram(f'Weights/{name}', param, epoch)\n",
    "                if param.grad is not None:\n",
    "                    writer.add_histogram(f'Gradients/{name}', param.grad, epoch)\n",
    "\n",
    "        if epoch % output_period == 0 or epoch == epochs-1:\n",
    "            print(f\"Epoch {epoch+1:2}/{epochs} -> \"\n",
    "                  f\"Train Loss: {train_loss:.4f} | Test Loss: {test_loss:2.4f} | \"\n",
    "                  f\"Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f} | \"\n",
    "                  f\"Accuracy: {accuracy:.3f} ---> Learning rate: \\x1b[31m{current_lr}\\x1b[0m\")\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_epoch = epoch+1\n",
    "            best_model_state = model.state_dict().copy()\n",
    "\n",
    "    if log_tensorboard:\n",
    "        writer.close()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, epochs+1), train_losses_data, 'b-o', linewidth=2, markersize=4, label=\"Training Loss\")\n",
    "    plt.plot(range(1, epochs+1), test_losses_data, 'r--s', linewidth=2, markersize=4, label=\"Test Loss\")\n",
    "    plt.title(\"Training Progress\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.xlabel(\"Epochs\", fontsize=12)\n",
    "    plt.ylabel(\"Loss\", fontsize=12)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.xticks(range(1, epochs+1, 5))\n",
    "    plt.annotate(f\"Final Train: {train_losses_data[-1]:.4f}\",\n",
    "                xy=(epochs, train_losses_data[-1]),\n",
    "                xytext=(epochs-0.1*epochs, train_losses_data[-1]),\n",
    "                arrowprops=dict(arrowstyle=\"->\"))\n",
    "    plt.annotate(f\"Final Test: {test_losses_data[-1]:.4f}\",\n",
    "                xy=(epochs, test_losses_data[-1]),\n",
    "                xytext=(epochs-0.1*epochs, test_losses_data[-1]*1.1),\n",
    "                arrowprops=dict(arrowstyle=\"->\"))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\nBest model from epoch {best_epoch} with F1: {best_f1:.4f}\")\n",
    "    print(f\"precision: {precision:.3f} | Recall: {recall:.3f} | Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "    return best_model_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1750081687630,
     "user": {
      "displayName": "teitur",
      "userId": "14435076508088469441"
     },
     "user_tz": 0
    },
    "id": "MmAhDnOOjgQ2",
    "outputId": "ea3c494b-a36a-4451-f40f-ec10bac2158a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch Output Dimensions:\n",
      "LEFT branch:\n",
      "\tOutput shape: torch.Size([1, 64, 14])\n",
      "\tFeatures per sample: 896\n",
      "\n",
      "RIGHT branch:\n",
      "\tOutput shape: torch.Size([1, 64, 6])\n",
      "\tFeatures per sample: 384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# class _Branch(nn.Module):\n",
    "#     def __init__(self, channel_sequence, kernel_sizes, paddings, strides, pool_sizes, pool_strides, dropout_rates):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = nn.Conv1d(1, channel_sequence[0], kernel_sizes[0], stride=strides[0], padding=paddings[0])\n",
    "#         self.conv2 = nn.Conv1d(channel_sequence[0], channel_sequence[1], kernel_sizes[1], stride=strides[1], padding=paddings[1])\n",
    "#         self.conv3 = nn.Conv1d(channel_sequence[1], channel_sequence[2], kernel_sizes[2], stride=strides[2], padding=paddings[2])\n",
    "\n",
    "#         self.pool1 = nn.MaxPool1d(pool_sizes[0], stride=pool_strides[0])\n",
    "#         self.pool2 = nn.MaxPool1d(pool_sizes[1], stride=pool_strides[1])\n",
    "\n",
    "#         self.dropout1 = nn.Dropout(dropout_rates[0])\n",
    "#         self.relu = nn.ReLU()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.relu(self.conv1(x))\n",
    "#         x = self.pool1(x)\n",
    "#         x = self.dropout1(x)\n",
    "\n",
    "#         x = self.relu(self.conv2(x))\n",
    "#         x = self.pool2(x)\n",
    "\n",
    "#         x = self.conv3(x)\n",
    "#         return x\n",
    "\n",
    "kz1 = 22\n",
    "kz2 = 400\n",
    "branch_configs = {\n",
    "    \"left\": {\n",
    "        \"channel_sequence\": [32, 64, 64],\n",
    "        \"kernel_sizes\": [kz1, 8, 8],\n",
    "        \"paddings\": [kz1//2 - 1, 3, 3],\n",
    "        \"strides\": [6, 1, 1],\n",
    "        \"pool_sizes\": [8, 4],\n",
    "        \"pool_strides\": [8, 4],\n",
    "        \"dropout_rates\": [0.1, 0.0]\n",
    "    },\n",
    "    \"right\": {\n",
    "        \"channel_sequence\": [32, 64, 64],\n",
    "        \"kernel_sizes\": [kz2, 8, 8],\n",
    "        \"paddings\": [kz2//2 - 1, 3, 3],\n",
    "        \"strides\": [50, 1, 1],\n",
    "        \"pool_sizes\": [4, 2],\n",
    "        \"pool_strides\": [4, 2],\n",
    "        \"dropout_rates\": [0.1, 0.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "n_samples = 3000\n",
    "dummy_input = torch.zeros(1, 1, n_samples)\n",
    "\n",
    "print(\"Branch Output Dimensions:\")\n",
    "for branch_name, config in branch_configs.items():\n",
    "    branch = _Branch(**config)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        output = branch(dummy_input)\n",
    "        features = output.numel() // output.shape[0]\n",
    "\n",
    "    print(f\"{branch_name.upper()} branch:\")\n",
    "    print(f\"\\tOutput shape: {output.shape}\")\n",
    "    print(f\"\\tFeatures per sample: {features}\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOVafylfdODk2Ey84W/pi+I",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
